% This file was created with Citavi 7.0.1.0

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Geschichtliches
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{azuma1997ar,
  author = {Azuma, Ronald T.},
  year = {1997},
  title = {A survey of augmented reality},
  pages = {355--385},
  volume = {6},
  number = {4},
  journal = {Presence: Teleoperators {\&} Virtual Environments}
}

@inproceedings{sutherland1965ultimateDisplay,
  author = {Sutherland, Ivan E.},
  title = {The Ultimate Display},
  pages = {506--508},
  publisher = {{Spartan Books}},
  booktitle = {Proceedings of the IFIP Congress},
  year = {1965}
}

@inproceedings{sutherland19683dDisplay,
  author = {Sutherland, Ivan E.},
  title = {A head-mounted three dimensional display},
  pages = {757--764},
  publisher = {AFIPS},
  booktitle = {Proceedings of the Fall Joint Computer Conference, Part I},
  year = {1968}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Einleitung
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@book{verma2022advances,
  title={Advances in Augmented Reality and Virtual Reality},
  author={Verma, J.K. and Paul, S.},
  isbn={9789811672200},
  series={Studies in Computational Intelligence},
  url={https://books.google.de/books?id=eWRXEAAAQBAJ},
  year={2022},
  publisher={Springer Nature Singapore}
}

@book{boulanger2024applications,
title = {Applications of Augmented Reality},
ISBN = {978-1-83769-334-4},
url = {https://doi.org/10.5772/intechopen.111231},
DOI = {10.5772/intechopen.111231},
publisher = {IntechOpen},
year = {2024},
address = {Rijeka},
author = {Pierre Boulanger},
}

@online{wikipedia2024pokemonGo,
 editor = {Wikipedia},
 title = {Pokémon Go},
 url = {https://de.wikipedia.org/wiki/Pok%C3%A9mon_Go},
 urldate = {2025-03-04},
}

@online{niantic2025pokemongo,
    author = {Niantic},
    title = {Pokémon im AR+-Modus fangen},
    urldate = {2025-03-04},
    url = {https://niantic.helpshift.com/hc/de/6-pokemon-go/faq/28-catching-pokemon-in-ar-mode-1712012768/?l=de}
}

@INPROCEEDINGS{chen2017medicalMR,
  author={Chen, Long and Day, Thomas W and Tang, Wen and John, Nigel W},
  booktitle={2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)}, 
  title={Recent Developments and Future Challenges in Medical Mixed Reality}, 
  year={2017},
  volume={},
  number={},
  pages={123-135},
  keywords={Virtual reality;Market research;Surgery;Mobile communication;Training;Databases},
  doi={10.1109/ISMAR.2017.29}}


@online{apple2023visionPro,
    author = {Apple},
    title = {Apple Vision Pro — Apples erster räumlicher Computer},
    urldate = {2025-03-04},
    url = {https://www.apple.com/de/newsroom/2023/06/introducing-apple-vision-pro/},
    year = {2023}
}

@online{meta2024quest,
    author = {Meta},
    title = {Das ist die Meta Quest},
    urldate = {2025-03-04},
    url = {https://www.meta.com/de/quest/},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Allgemein
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@book{szeliski2022computerVision,
  title     = {Computer Vision: Algorithms and Applications},
  author    = {Richard Szeliski},
  publisher = {Springer},
  year      = {2022},
  edition   = {2nd},
  isbn      = {978-3-030-34372-9},
  doi       = {10.1007/978-3-030-34372-9},
}

@book{doerner2022virtual,
  title     = {Virtual and Augmented Reality (VR/AR): Foundations and Methods of Extended Realities (XR)},
  editor    = {Ralf Doerner and Wolfgang Broll and Paul Grimm and Bernhard Jung},
  publisher = {Springer},
  year      = {2022},
  isbn      = {978-3-030-79061-5},
  doi       = {10.1007/978-3-030-79062-2},
}

@online{appledevdoc,
  abstract = {Browse the latest sample code, articles, tutorials, and API reference.},
  author = {Apple},
  title = {Featured | Apple Developer Documentation},
  url = {https://developer.apple.com/documentation/},
  urldate = {2025-02-03},
  year = {2025},
}

@online{arcoredevdoc,
  author = {Google},
  title = {ARCore | Google Developers},
  url = {https://developers.google.com/ar/develop?hl=de/},
  urldate = {2025-02-19},
  year = {2025},
}

@book{nhan2022masteringARKit,
  title     = {Mastering ARKit: Apple's Augmented Reality App Development Platform},
  author    = {Jayven Nhan},
  publisher = {Apress},
  year      = {2022},
  isbn      = {978-1-4842-7835-2},
}

@manual{brunata2023handbuch,
  organization = {BRUNATA-METRONA GmbH \& Co. KG},
  title = {Handbuch zur Montage von Rauchmeldern},
  year = {2023},
  note = {Interne Dokumentation, nicht öffentlich zugänglich}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Dreidimensional Computergrafik
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@online{wikipedia2023polygons,
 author = {Wikipedia},
 title = {Polygonal modeling},
 url = {https://en.wikipedia.org/w/index.php?title=Polygonal_modeling&oldid=1185415049},
 urldate = {2025-02-03},
}

@online{wikipedia2023mesh,
 author = {Wikipedia},
 title = {Polygon mesh},
 url = {https://en.wikipedia.org/wiki/Polygon_mesh},
 urldate = {2025-02-04},
}

@online{espinoza2024graphics,
 author = {Juan Espinoza},
 year = {2024},
 title = {3D Graphics: A Beginners Guide},
 url = {https://medium.com/@jrespinozah/3d-graphics-a-beginners-guide-dbd8e2a0306a},
 urldate = {2025-02-04}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Coordinate-Systems
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@online{usau2023appleARCamera,
 author = {Vitali Usau},
 year = {2023},
 title = {Apple ARCamera. Camera parameters explanation for 3D reconstruction pipeline},
 url = {https://medium.com/@vitali.usau/apple-arcamera-camera-parameters-explanation-for-3d-reconstruction-pipeline-7b3937dab3b9},
 urldate = {2025-02-03}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Matrix-Algebra
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@online{pezzi2021matrices,
 abstract = {In this short lecture I want to explain why programmers use 4x4 matrices to apply 3D transformations in computer graphics.We will learn why we need a 4x4 mat...},
 author = {Gustavo Pezzi},
 year = {2021},
 title = {Math for Game Developers: Why do we use 4x4 Matrices in 3D Graphics?},
 url = {https://www.youtube.com/watch?v=Do_vEjd6gF0},
 urldate = {2025-02-03}
}

@online{freescale2010math3d,
 author = {{Freescale Semiconductor, Inc.}},
 title = {3D Math Overview and 3D Graphics Foundations},
 url = {https://www.nxp.com/docs/en/application-note/AN4132.pdf},
 year = {2010},
 urldate = {2025-02-03},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Calibration
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@online{li2023calibration,
  author = {Computer Vision II: Multiple View Geometry (IN2228)},
  title = {Dr. Haoang Li},
  year = {2023},
  note = {Lecture script, TUM},
  url = {https://cvg.ci t.tum.de/_media/teaching/ss2023/mvg2023/material/chapter04_camera_calibration.pdf},
  urldate = {2025-02-07},
}

@online{mw2024calibration,
  author = {MathWorks},
  year = {2024},
  title = {What Is Camera Calibration?},
  url = {https://de.mathworks.com/help/vision/ug/camera-calibration.html},
  urldate = {2025-02-07}
}

@online{alam2024calibration,
 year = {2024},
 title = {Camera Calibration Explained: Enhancing Accuracy in Computer Vision Applications},
 author = {Md Faruk Alam},
 url = {https://farukalamai.medium.com/camera-calibration-explained-enhancing-accuracy-in-computer-vision-applications-8ad1494cc5f2},
 urldate = {2025-02-07}
}

@article{brown1966distortion,
	title = {Decentering {Distortion} of {Lenses}},
	volume = {32},
	number = {3},
	journal = {Photometric Engineering},
	author = {Brown, D. C.},
	year = {1966},
	pages = {444--462},
}

@online{stachniss2021calibration,
 year = {2021},
 title = {Camera Calibration:
Zhang's Method},
 author = {Cyrill Stachniss},
 url = {https://www.ipb.uni-bonn.de/html/teaching/photo12-2021/2021-pho1-22-Zhang-calibration.pptx.pdf},
 urldate = {2025-03-04}
}

@inproceedings{zhang1999calibration,
  author={Zhengyou Zhang},
  booktitle={Proceedings of the Seventh IEEE International Conference on Computer Vision}, 
  title={Flexible camera calibration by viewing a plane from unknown orientations}, 
  year={1999},
  volume={1},
  number={},
  pages={666-673 vol.1},
  keywords={Cameras;Calibration;Computer vision;Layout;Lenses;Nonlinear distortion;Computer simulation;Testing;Voltage control;Robustness},
  doi={10.1109/ICCV.1999.791289}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Sensorik
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@online{wikipedia2024dof,
author = {Wikipedia},
 year = {2024},
 title = {Degrees of freedom (mechanics)},
 url = {https://en.wikipedia.org/w/index.php?title=Degrees_of_freedom_(mechanics)&oldid=1236488869},
 urldate = {2025-03-02},
}

@online{ibm2024lidar,
 year = {2024},
 title = {Was ist LiDAR?},
 url = {https://www.ibm.com/de-de/topics/lidar},
 urldate = {2025-03-04},
}

@online{wikipedia2024tracking,
author = {Wikipedia},
 year = {2024},
 title = {Tracking (Spurverfolgung)},
 url = {https://de.wikipedia.org/wiki/Tracking_(Spurverfolgung)},
 urldate = {2025-03-05},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SLAM
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@Book{gao2021vSLAM,
  title     = {Introduction to Visual SLAM: From Theory to Practice},
  author    = {Xiang Gao and Tao Zhang},
  publisher = {Springer},
  year      = {2021},
  isbn      = {978-981-16-4938-7},
}

@online{karanjai2018slam,
 author = {{Rabimba Karanjai}},
 year = {2018},
 title = {ARCore and Arkit, What is under the hood: SLAM (Part 2)},
 url = {https://medium.com/@rabimba/arcore-and-arkit-what-is-under-the-hood-slam-part-2-5a5271d30449},
 urldate = {2025-02-17}
}

@article{cadena2016slam,
  author={Cadena, Cesar and Carlone, Luca and Carrillo, Henry and Latif, Yasir and Scaramuzza, Davide and Neira, José and Reid, Ian and Leonard, John J.},
  journal={IEEE Transactions on Robotics}, 
  title={Past, Present, and Future of Simultaneous Localization and Mapping: Toward the Robust-Perception Age}, 
  year={2016},
  volume={32},
  number={6},
  pages={1309-1332},
  keywords={Graph theory;Simultaneous location and mapping;Service robots;Robustness;Localization;Factor graphs;localization;mapping;maximum a posteriori estimation;perception;robots;sensing;simultaneous localization and mapping (SLAM)},
  doi={10.1109/TRO.2016.2624754}
}

%%%%%%%%%%%%%%%%%%%%%%Feature Detection/Matching%%%%%%%%%%%%%%%%%%%%%%%%%%%

@online{kukil2022featureMatching,
  author = {Kukil},
  title = {How to build Chrome Dino game bot using OpenCV Feature Matching},
  year = {2022},
  urldate = {2025-03-05},
}

@online{ghosh2024fmNN,
  author = {Ankan Ghosh},
  title = {Introduction to Feature Matching Using Neural Networks},
  year = {2024},
  urldate = {2025-03-05},
}

@article{tourani2022vSLAMTrends,
   title={Visual SLAM: What Are the Current Trends and What to Expect?},
   volume={22},
   ISSN={1424-8220},
   url={http://dx.doi.org/10.3390/s22239297},
   DOI={10.3390/s22239297},
   number={23},
   journal={Sensors},
   publisher={MDPI AG},
   author={Tourani, Ali and Bavle, Hriday and Sanchez-Lopez, Jose Luis and Voos, Holger},
   year={2022},
   month=nov, pages={9297} }

@INPROCEEDINGS{rublee2011orb,
  author={Rublee, Ethan and Rabaud, Vincent and Konolige, Kurt and Bradski, Gary},
  booktitle={2011 International Conference on Computer Vision}, 
  title={ORB: An efficient alternative to SIFT or SURF}, 
  year={2011},
  volume={},
  number={},
  pages={2564-2571},
  keywords={Boats},
  doi={10.1109/ICCV.2011.6126544}
  }


@inproceedings{rosten2006fast,
author="Rosten, Edward
and Drummond, Tom",
editor="Leonardis, Ale{\v{s}}
and Bischof, Horst
and Pinz, Axel",
title="Machine Learning for High-Speed Corner Detection",
booktitle="Computer Vision -- ECCV 2006",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="430--443",
abstract="Where feature points are used in real-time frame-rate applications, a high-speed feature detector is necessary. Feature detectors such as SIFT (DoG), Harris and SUSAN are good methods which yield high quality features, however they are too computationally intensive for use in real-time applications of any complexity. Here we show that machine learning can be used to derive a feature detector which can fully process live PAL video using less than 7{\%} of the available processing time. By comparison neither the Harris detector (120{\%}) nor the detection stage of SIFT (300{\%}) can operate at full frame rate.",
isbn="978-3-540-33833-8"
}

@InProceedings{calonder2010brief,
author="Calonder, Michael
and Lepetit, Vincent
and Strecha, Christoph
and Fua, Pascal",
editor="Daniilidis, Kostas
and Maragos, Petros
and Paragios, Nikos",
title="BRIEF: Binary Robust Independent Elementary Features",
booktitle="Computer Vision -- ECCV 2010",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="778--792",
abstract="We propose to use binary strings as an efficient feature point descriptor, which we call BRIEF.We show that it is highly discriminative even when using relatively few bits and can be computed using simple intensity difference tests. Furthermore, the descriptor similarity can be evaluated using the Hamming distance, which is very efficient to compute, instead of the L2 norm as is usually done.",
isbn="978-3-642-15561-1"
}

@online{wikipedia2024moment,
 author = {Wikipedia},
 year = {2024},
 title = {Moment (Bildverarbeitung)},
 url = {https://de.wikipedia.org/wiki/Moment_(Bildverarbeitung)},
 urldate = {2025-03-05},
}

@inproceedings{muja2009flann,
  author    = {Marius Muja and David G. Lowe},
  title     = {Fast Approximate Nearest Neighbors with Automatic Algorithm Configuration},
  booktitle = {International Conference on Computer Vision Theory and Application 
               VISSAPP'09)},
  publisher = {INSTICC Press},
  year      = {2009},
  pages     = {331-340}
}

@inproceedings{lowe1999sift,
  author={Lowe, D.G.},
  booktitle={Proceedings of the Seventh IEEE International Conference on Computer Vision}, 
  title={Object recognition from local scale-invariant features}, 
  year={1999},
  volume={2},
  number={},
  pages={1150-1157 vol.2},
  keywords={Object recognition;Electrical capacitance tomography;Image recognition;Lighting;Neurons;Computer science;Reactive power;Filters;Programmable logic arrays;Layout},
  doi={10.1109/ICCV.1999.790410}
  }

@inproceedings{bay2006surf,
author="Bay, Herbert
and Tuytelaars, Tinne
and Van Gool, Luc",
editor="Leonardis, Ale{\v{s}}
and Bischof, Horst
and Pinz, Axel",
title="SURF: Speeded Up Robust Features",
booktitle="Computer Vision -- ECCV 2006",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="404--417",
abstract="In this paper, we present a novel scale- and rotation-invariant interest point detector and descriptor, coined SURF (Speeded Up Robust Features). It approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster.",
isbn="978-3-540-33833-8"
}

%%%%%%%%%%%%%%%%%%%%%%Pose Estimation%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@online{stachniss2020FandEmatrix,
 abstract = {Fundamental and essential matrix explained in 5 minutesSeries: 5 Minutes with CyrillCyrill Stachniss, 2020Credits:Video by Cyrill StachnissIntro music by The...},
 author = {Cyrill Stachniss},
 year = {2020},
 title = {Fundamental and Essential Matrix - 5 Minutes with Cyrill},
 url = {https://www.youtube.com/watch?v=auhpPoAqprk},
 urldate = {2025-02-17}
}

@ARTICLE{tsai1984svd,
  author={Tsai, Roger Y. and Huang, Thomas S.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Uniqueness and Estimation of Three-Dimensional Motion Parameters of Rigid Objects with Curved Surfaces}, 
  year={1984},
  volume={PAMI-6},
  number={1},
  pages={13-27},
  keywords={Motion estimation;Nonlinear equations;Image analysis;Image sequence analysis;Motion analysis;Image motion analysis;Cameras;Geometry;Singular value decomposition;Matrix decomposition;Dynamic scene analysis;image sequence analysis;motion estimation;motion stereo;optical flow},
  doi={10.1109/TPAMI.1984.4767471}
}

@article{hartley1997eightpoint,
  author={Hartley, R.I.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={In defense of the eight-point algorithm}, 
  year={1997},
  volume={19},
  number={6},
  pages={580-593},
  keywords={Iterative algorithms;Layout;Cameras;Equations;Image reconstruction;Algorithm design and analysis;Stereo vision;Computer vision;Least squares methods},
  doi={10.1109/34.601246}
}

@online{kitani2017essentialMatrix,
  author = {Kris Kitani},
  title = {Essential Matrix},
  year = {2017},
  url = {https://www.cs.cmu.edu/~16385/s17/Slides/12.2_Essential_Matrix.pdf},
  urldate = {2025-02-19}
}

%%%%%%%%%%%%%%%%%%%%%Triangulation%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@techreport{yang2010planeDetection,
title = {Plane Detection in Point Cloud Data},
abstract = {Plane detection is a prerequisite to a wide variety of vision tasks. RANdomSAmple Consensus (RANSAC) algorithm is widely used for plane detectionin point cloud data. Minimum description length (MDL) principle is used todeal with several competing hypothesis. This paper presents a new approachto the plane detection by integrating RANSAC and MDL. The method couldavoid detecting wrong planes due to the complex geometry of the 3D data.The paper tests the performance of proposed method on both synthetic andreal data.},
author = {Yang, {Michael Ying} and Wolfgang Förstner},
year = {2010},
language = {Undefined},
series = {IGG : Technical Report},
publisher = {University of Bonn},
pages = {1--16},
type = {WorkingPaper},
institution = {University of Bonn},
}

@online{ajith2020ransac,
 author = {Raj Ajith},
 year = {2020},
 title = {3D RANSAC Algorithm for Lidar PCD Segmentation},
 url = {https://medium.com/@ajithraj_gangadharan/3d-ransac-algorithm-for-lidar-pcd-segmentation-315d2a51351},
 urldate = {2025-03-06}
}

@inproceedings{kazhdan2006poisson,
  abstract = {We show that surface reconstruction from oriented points can be cast as a spatial Poisson problem. This Poisson formulation considers all the points at once, without resorting to heuristic spatial partitioning or blending, and is therefore highly resilient to data noise. Unlike radial basis function schemes, our Poisson approach allows a hierarchy of locally supported basis functions, and therefore the solution reduces to a well conditioned sparse linear system. We describe a spatially adaptive multiscale algorithm whose time and space complexities are proportional to the size of the reconstructed model. Experimenting with publicly available scan data, we demonstrate reconstruction of surfaces with greater detail than previously achievable.},
  acmid = {1281965},
  added-at = {2018-11-13T02:38:38.000+0100},
  address = {Aire-la-Ville, Switzerland, Switzerland},
  author = {Kazhdan, Michael M. and Bolitho, Matthew and Hoppe, Hugues},
  biburl = {https://www.bibsonomy.org/bibtex/2faa91f1a0d59361cc4e3cbdb41de6376/jbayardo},
  booktitle = {Proceedings of the Fourth Eurographics Symposium on Geometry Processing},
  description = {Poisson surface reconstruction},
  editor = {Sheffer, Alla and Polthier, Konrad},
  interhash = {a4b2fa4540bbf7906dc93e03f62aa4f1},
  intrahash = {faa91f1a0d59361cc4e3cbdb41de6376},
  isbn = {3-905673-36-3},
  keywords = {3d-reconstruction fitting},
  location = {Cagliari, Sardinia, Italy},
  numpages = {10},
  pages = {61-70},
  publisher = {Eurographics Association},
  series = {SGP '06},
  timestamp = {2018-11-13T02:38:38.000+0100},
  title = {Poisson Surface Reconstruction},
  url = {http://dl.acm.org/citation.cfm?id=1281957.1281965},
  volume = 256,
  year = 2006
}

@online{open3d2025pointcloud,
  author = {open3d},
  url = {https://www.open3d.org/docs/latest/tutorial/geometry/pointcloud.html},
  title = {Point cloud},
  urldate = {2025-03-06},
}


%%%%%%%%%%%%%%%%%%%%%Bundle Adjustment%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@online{levenberg2024minimization,
 author = {Wikipedia},
 year = {2024},
 title = {Levenberg-Marquardt-Algorithmus},
 url = {https://de.wikipedia.org/wiki/Levenberg-Marquardt-Algorithmus},
 urldate = {2025-03-06},
}

@online{kumar2024bundleAdjustment,
 author = {Dhiraj Kumar},
 year = {2024},
 title = {What Is Bundle Adjustment?},
 url = {https://www.baeldung.com/cs/computer-vision-bundle-adjustment},
 urldate = {2025-03-06},
}

%%%%%%%%%%%%%%%%%%%%%%Loop Closure%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@online{yoon2024BoW,
  author = {Sung-Eui Yoon},
  url = {https://sgvr.kaist.ac.kr/~sungeui/IR_F14/NewSlides/Lec4b-bow.pdf},
  title = {Bag-of-Words (BoW) Models},
  year = {2024},
  urldate = {2025-02-17},
}


@online{wikipedia2025clusteranalyse,
   author = "Wikipedia",
   title = "Clusteranalyse --- Wikipedia{,} die freie Enzyklopädie",
   year = "2025",
   url = "https://de.wikipedia.org/w/index.php?title=Clusteranalyse&oldid=252310027",
   urldate = {2025-02-17}
}

@inproceedings{khan2015ibuild,
  author={Khan, Sheraz and Wollherr, Dirk},
  booktitle={2015 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={IBuILD: Incremental bag of Binary words for appearance based loop closure detection}, 
  year={2015},
  volume={},
  number={},
  pages={5441-5447},
  keywords={Visualization;Indexes;Vocabulary;Feature extraction;Robots;Pipelines;Merging},
  doi={10.1109/ICRA.2015.7139959}
}

@online{ta2023loopClosure,
   author = "Think Autonomous",
   title = "Introduction to Loop Closure Detection in SLAM",
   year = "2025",
   url = "https://www.thinkautonomous.ai/blog/loop-closure/",
   urldate = {2025-03-06}
}

@misc{teynor2024ml,
  author = {Prof. Dr.-Ing. Alexandra Teynor},
  title = {Maschinelles Lernen und Mustererkennung - Vorlesungsskript},
  year = {2024},
}

 %%%%%%%%%%%%%%%%%%%%%Scene Understanding%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

 @article{long2014fcnn,
  author       = {Jonathan Long and
                  Evan Shelhamer and
                  Trevor Darrell},
  title        = {Fully Convolutional Networks for Semantic Segmentation},
  journal      = {CoRR},
  volume       = {abs/1411.4038},
  year         = {2014},
  url          = {http://arxiv.org/abs/1411.4038},
  eprinttype    = {arXiv},
  eprint       = {1411.4038},
  timestamp    = {Mon, 13 Aug 2018 16:48:17 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/LongSD14.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ronneberger2015unet,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% LIV-SLAM
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{zhang2024lidarslam,
author = {Zhang, Yongjun and Shi, Pengcheng and Li, Jiayuan},
title = {3D LiDAR SLAM: A survey},
journal = {The Photogrammetric Record},
volume = {39},
number = {186},
pages = {457-517},
keywords = {benchmark, LiDAR simultaneous localization and mapping (SLAM), loop closure detection, multi-sensor fusion, odometry},
doi = {https://doi.org/10.1111/phor.12497},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/phor.12497},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/phor.12497},
abstract = {Abstract Simultaneous localization and mapping (SLAM) is a very challenging yet fundamental problem in the field of robotics and photogrammetry, and it is also a prerequisite for intelligent perception of unmanned systems. In recent years, 3D LiDAR SLAM technology has made remarkable progress. However, to the best of our knowledge, almost all existing surveys focus on visual SLAM methods. To bridge the gap, this paper provides a comprehensive review that summarizes the scientific connotation, key difficulties, research status, and future trends of 3D LiDAR SLAM, aiming to give readers a better understanding of LiDAR SLAM technology, thereby inspiring future research. Specifically, it summarizes the contents and characteristics of the main steps of LiDAR SLAM, introduces the key difficulties it faces, and gives the relationship with existing reviews; it provides an overview of current research hotspots, including LiDAR-only methods and multi-sensor fusion methods, and gives milestone algorithms and open-source tools in each category; it summarizes common datasets, evaluation metrics and representative commercial SLAM solutions, and provides the evaluation results of mainstream methods on public datasets; it looks forward to the development trend of LiDAR SLAM, and considers the preliminary ideas of multi-modal SLAM, event SLAM, and quantum SLAM.},
year = {2024}
}

@online{bogoslavskyi2017icp,
  author = {Igor Bogoslavskyi},
  title = {ICP},
  url = {https://nbviewer.org/github/niosus/notebooks/blob/master/icp.ipynb},
  year = {2017},
  urldate = {2025-03-06}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Umsetzung
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@online{cobb2019focusEntity,
 abstract = {Bringing the scanning box from SceneKit to RealityKit - maxxfrazer/FocusEntity},
 author = {Max Fraser Cobb},
 year = {2019},
 title = {maxxfrazer/FocusEntity: Bringing the scanning box from SceneKit to RealityKit},
 url = {https://github.com/maxxfrazer/FocusEntity},
 urldate = {2025-03-02}
}

@online{apple2025swift,
 author = {Apple},
 year = {2025},
 title = {Swift Documentation},
 url = {https://www.swift.org/documentation/},
 urldate = {2025-03-06}
}

@online{wikipedia2024mvvm,
 author = {Wikipedia},
 year = {2024},
 title = {Model View ViewModel},
 url = {https://de.wikipedia.org/wiki/Model_View_ViewModel},
 urldate = {2025-03-18}
}

@online{yuen2024raycasting,
 author = {Deborah Yuen},
 year = {2024},
 title = {HW 8: Raycasting},
 url = {https://ctin583.usc.edu/sp24/Homework/hw08/},
 urldate = {2025-03-18}
}
